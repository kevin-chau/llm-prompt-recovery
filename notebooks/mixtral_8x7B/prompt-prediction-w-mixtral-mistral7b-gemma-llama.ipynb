{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "578c8373",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-03-22T21:50:54.199898Z",
     "iopub.status.busy": "2024-03-22T21:50:54.199053Z",
     "iopub.status.idle": "2024-03-22T21:52:58.272741Z",
     "shell.execute_reply": "2024-03-22T21:52:58.271690Z"
    },
    "papermill": {
     "duration": 124.087589,
     "end_time": "2024-03-22T21:52:58.275517",
     "exception": false,
     "start_time": "2024-03-22T21:50:54.187928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/making-wheels-of-necessary-packages-for-hf-llms\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-hf-llms/bitsandbytes-0.42.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes==0.42.0) (1.11.4)\r\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /opt/conda/lib/python3.10/site-packages (from scipy->bitsandbytes==0.42.0) (1.26.4)\r\n",
      "Installing collected packages: bitsandbytes\r\n",
      "Successfully installed bitsandbytes-0.42.0\r\n",
      "Looking in links: /kaggle/input/making-wheels-of-necessary-packages-for-hf-llms\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-hf-llms/accelerate-0.27.2-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (21.3)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (5.9.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (6.0.1)\r\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (2.1.2)\r\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (0.20.3)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate==0.27.2) (0.4.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate==0.27.2) (3.1.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate==0.27.2) (2024.2.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.27.2) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->accelerate==0.27.2) (4.66.1)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate==0.27.2) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.27.2) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.27.2) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.27.2) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate==0.27.2) (2024.2.2)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate==0.27.2) (1.3.0)\r\n",
      "accelerate is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\r\n",
      "Looking in links: /kaggle/input/making-wheels-of-necessary-packages-for-hf-llms\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-hf-llms/transformers-4.38.1-py3-none-any.whl\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (3.13.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (0.20.3)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (0.15.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (0.4.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.38.1) (4.66.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.1) (2024.2.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.1) (4.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.38.1) (3.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.1) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.1) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.1) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.38.1) (2024.2.2)\r\n",
      "transformers is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\r\n",
      "Looking in links: /kaggle/input/making-wheels-of-necessary-packages-for-hf-llms\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-hf-llms/optimum-1.17.1-py3-none-any.whl\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-hf-llms/coloredlogs-15.0.1-py2.py3-none-any.whl (from optimum==1.17.1)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum==1.17.1) (1.12)\r\n",
      "Requirement already satisfied: transformers>=4.26.0 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum==1.17.1) (4.38.1)\r\n",
      "Requirement already satisfied: torch>=1.11 in /opt/conda/lib/python3.10/site-packages (from optimum==1.17.1) (2.1.2)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from optimum==1.17.1) (21.3)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from optimum==1.17.1) (1.26.4)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from optimum==1.17.1) (0.20.3)\r\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from optimum==1.17.1) (2.1.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum==1.17.1) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum==1.17.1) (2024.2.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum==1.17.1) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum==1.17.1) (4.66.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum==1.17.1) (6.0.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.8.0->optimum==1.17.1) (4.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->optimum==1.17.1) (3.1.1)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum==1.17.1) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11->optimum==1.17.1) (3.1.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.0->transformers[sentencepiece]>=4.26.0->optimum==1.17.1) (2023.12.25)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.0->transformers[sentencepiece]>=4.26.0->optimum==1.17.1) (0.15.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.26.0->transformers[sentencepiece]>=4.26.0->optimum==1.17.1) (0.4.2)\r\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum==1.17.1) (0.2.0)\r\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum==1.17.1) (3.20.3)\r\n",
      "Processing /kaggle/input/making-wheels-of-necessary-packages-for-hf-llms/humanfriendly-10.0-py2.py3-none-any.whl (from coloredlogs->optimum==1.17.1)\r\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.17.1) (11.0.0)\r\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.17.1) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.17.1) (2.1.4)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.17.1) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.17.1) (0.70.16)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.17.1) (3.9.1)\r\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->optimum==1.17.1) (0.18.0)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum==1.17.1) (1.3.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.17.1) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.17.1) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.17.1) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.17.1) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.17.1) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->optimum==1.17.1) (4.0.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum==1.17.1) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum==1.17.1) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum==1.17.1) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.8.0->optimum==1.17.1) (2024.2.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11->optimum==1.17.1) (2.1.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum==1.17.1) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum==1.17.1) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->optimum==1.17.1) (2023.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum==1.17.1) (1.16.0)\r\n",
      "Installing collected packages: humanfriendly, coloredlogs, optimum\r\n",
      "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 optimum-1.17.1\r\n",
      "Looking in links: /kaggle/input/k/kevinchau321/making-wheels-of-necessary-packages-for-hf-llms\r\n",
      "Processing /kaggle/input/k/kevinchau321/making-wheels-of-necessary-packages-for-hf-llms/peft-0.9.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.9.0) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.9.0) (21.3)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.9.0) (5.9.3)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.9.0) (6.0.1)\r\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.9.0) (2.1.2)\r\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.9.0) (4.38.1)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.9.0) (4.66.1)\r\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.9.0) (0.27.2)\r\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.9.0) (0.4.2)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.17.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.9.0) (0.20.3)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.9.0) (3.13.1)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.9.0) (2024.2.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.9.0) (2.31.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.17.0->peft==0.9.0) (4.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.9.0) (3.1.1)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.9.0) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.9.0) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.9.0) (3.1.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.9.0) (2023.12.25)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.9.0) (0.15.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.9.0) (2.1.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.9.0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.9.0) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.9.0) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.17.0->peft==0.9.0) (2024.2.2)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.9.0) (1.3.0)\r\n",
      "Installing collected packages: peft\r\n",
      "Successfully installed peft-0.9.0\r\n",
      "Looking in links: /kaggle/input/k/kevinchau321/making-wheels-of-necessary-packages-for-hf-llms\r\n",
      "Processing /kaggle/input/k/kevinchau321/making-wheels-of-necessary-packages-for-hf-llms/trl-0.8.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.8.0) (2.1.2)\r\n",
      "Requirement already satisfied: transformers>=4.31.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.8.0) (4.38.1)\r\n",
      "Requirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl==0.8.0) (1.26.4)\r\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl==0.8.0) (0.27.2)\r\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl==0.8.0) (2.1.0)\r\n",
      "Processing /kaggle/input/k/kevinchau321/making-wheels-of-necessary-packages-for-hf-llms/tyro-0.7.3-py3-none-any.whl (from trl==0.8.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.0) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.0) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.0) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.0) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.0) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.8.0) (2024.2.0)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.0) (0.20.3)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.0) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.0) (6.0.1)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.0) (2023.12.25)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.0) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.0) (0.15.2)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.0) (0.4.2)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.31.0->trl==0.8.0) (4.66.1)\r\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.0) (0.15)\r\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl==0.8.0) (13.7.0)\r\n",
      "Processing /kaggle/input/k/kevinchau321/making-wheels-of-necessary-packages-for-hf-llms/shtab-1.7.1-py3-none-any.whl (from tyro>=0.5.11->trl==0.8.0)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl==0.8.0) (5.9.3)\r\n",
      "Requirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.0) (11.0.0)\r\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.0) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.0) (2.1.4)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.0) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.0) (0.70.16)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.0) (3.9.1)\r\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.8.0) (0.18.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.0) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.0) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.0) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.0) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.0) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.8.0) (4.0.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.31.0->trl==0.8.0) (3.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.0) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.0) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.31.0->trl==0.8.0) (2024.2.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.0) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.8.0) (2.17.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl==0.8.0) (2.1.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.8.0) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.8.0) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.8.0) (2023.4)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl==0.8.0) (1.3.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.8.0) (0.1.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.8.0) (1.16.0)\r\n",
      "Installing collected packages: shtab, tyro, trl\r\n",
      "Successfully installed shtab-1.7.1 trl-0.8.0 tyro-0.7.3\r\n",
      "Looking in links: /kaggle/input/k/kevinchau321/making-wheels-of-necessary-packages-for-hf-llms\r\n",
      "Processing /kaggle/input/k/kevinchau321/making-wheels-of-necessary-packages-for-hf-llms/datasets-2.18.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (3.13.1)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (1.26.4)\r\n",
      "Processing /kaggle/input/k/kevinchau321/making-wheels-of-necessary-packages-for-hf-llms/pyarrow-15.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (from datasets==2.18.0)\r\n",
      "Processing /kaggle/input/k/kevinchau321/making-wheels-of-necessary-packages-for-hf-llms/pyarrow_hotfix-0.6-py3-none-any.whl (from datasets==2.18.0)\r\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (0.3.8)\r\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (2.1.4)\r\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (2.31.0)\r\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (4.66.1)\r\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (3.4.1)\r\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (0.70.16)\r\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets==2.18.0) (2024.2.0)\r\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (3.9.1)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (0.20.3)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.18.0) (6.0.1)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (23.2.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (1.9.3)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (1.3.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.18.0) (4.0.3)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets==2.18.0) (4.9.0)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets==2.18.0) (3.1.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.18.0) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.18.0) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.18.0) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.18.0) (2024.2.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.18.0) (2023.4)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.18.0) (1.16.0)\r\n",
      "Installing collected packages: pyarrow-hotfix, pyarrow, datasets\r\n",
      "  Attempting uninstall: pyarrow\r\n",
      "    Found existing installation: pyarrow 11.0.0\r\n",
      "    Uninstalling pyarrow-11.0.0:\r\n",
      "      Successfully uninstalled pyarrow-11.0.0\r\n",
      "  Attempting uninstall: datasets\r\n",
      "    Found existing installation: datasets 2.1.0\r\n",
      "    Uninstalling datasets-2.1.0:\r\n",
      "      Successfully uninstalled datasets-2.1.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cudf 23.8.0 requires cubinlinker, which is not installed.\r\n",
      "cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cudf 23.8.0 requires ptxcompiler, which is not installed.\r\n",
      "cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\r\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.2 which is incompatible.\r\n",
      "beatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.1.2 which is incompatible.\r\n",
      "cudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\r\n",
      "cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\r\n",
      "cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\r\n",
      "cudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.2 which is incompatible.\r\n",
      "cuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\r\n",
      "dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed datasets-2.18.0 pyarrow-15.0.2 pyarrow-hotfix-0.6\r\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "# If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed\n",
    "!pip install --no-index /kaggle/input/making-wheels-of-necessary-packages-for-hf-llms/bitsandbytes-0.42.0-py3-none-any.whl --find-links=/kaggle/input/making-wheels-of-necessary-packages-for-hf-llms\n",
    "!pip install --no-index /kaggle/input/making-wheels-of-necessary-packages-for-hf-llms/accelerate-0.27.2-py3-none-any.whl --find-links=/kaggle/input/making-wheels-of-necessary-packages-for-hf-llms\n",
    "!pip install --no-index /kaggle/input/making-wheels-of-necessary-packages-for-hf-llms/transformers-4.38.1-py3-none-any.whl --find-links=/kaggle/input/making-wheels-of-necessary-packages-for-hf-llms\n",
    "!pip install --no-index /kaggle/input/making-wheels-of-necessary-packages-for-hf-llms/optimum-1.17.1-py3-none-any.whl --find-links=/kaggle/input/making-wheels-of-necessary-packages-for-hf-llms\n",
    "!pip install --no-index /kaggle/input/k/kevinchau321/making-wheels-of-necessary-packages-for-hf-llms/peft-0.9.0-py3-none-any.whl --find-links=/kaggle/input/k/kevinchau321/making-wheels-of-necessary-packages-for-hf-llms\n",
    "!pip install --no-index /kaggle/input/k/kevinchau321/making-wheels-of-necessary-packages-for-hf-llms/trl-0.8.0-py3-none-any.whl --find-links=/kaggle/input/k/kevinchau321/making-wheels-of-necessary-packages-for-hf-llms\n",
    "!pip install --no-index /kaggle/input/k/kevinchau321/making-wheels-of-necessary-packages-for-hf-llms/datasets-2.18.0-py3-none-any.whl --find-links=/kaggle/input/k/kevinchau321/making-wheels-of-necessary-packages-for-hf-llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "727d0d16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T21:52:58.309582Z",
     "iopub.status.busy": "2024-03-22T21:52:58.309167Z",
     "iopub.status.idle": "2024-03-22T21:53:01.173501Z",
     "shell.execute_reply": "2024-03-22T21:53:01.172219Z"
    },
    "papermill": {
     "duration": 2.88459,
     "end_time": "2024-03-22T21:53:01.176203",
     "exception": false,
     "start_time": "2024-03-22T21:52:58.291613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B disabled.\r\n"
     ]
    }
   ],
   "source": [
    "!wandb disabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c49fefae",
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-03-22T21:53:01.209446Z",
     "iopub.status.busy": "2024-03-22T21:53:01.209111Z",
     "iopub.status.idle": "2024-03-22T21:53:24.173469Z",
     "shell.execute_reply": "2024-03-22T21:53:24.172176Z"
    },
    "papermill": {
     "duration": 22.983796,
     "end_time": "2024-03-22T21:53:24.176451",
     "exception": false,
     "start_time": "2024-03-22T21:53:01.192655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-22 21:53:14.688803: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-22 21:53:14.688904: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-22 21:53:14.865094: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "from accelerate.utils import BnbQuantizationConfig\n",
    "from accelerate import Accelerator\n",
    "import transformers\n",
    "from transformers import TrainingArguments\n",
    "import optimum\n",
    "import bitsandbytes\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
    "from trl import SFTTrainer\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83a27772",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T21:53:24.212031Z",
     "iopub.status.busy": "2024-03-22T21:53:24.210459Z",
     "iopub.status.idle": "2024-03-22T21:53:24.216054Z",
     "shell.execute_reply": "2024-03-22T21:53:24.215012Z"
    },
    "papermill": {
     "duration": 0.025033,
     "end_time": "2024-03-22T21:53:24.218238",
     "exception": false,
     "start_time": "2024-03-22T21:53:24.193205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "start_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b257eb27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T21:53:24.251275Z",
     "iopub.status.busy": "2024-03-22T21:53:24.250916Z",
     "iopub.status.idle": "2024-03-22T21:53:24.255411Z",
     "shell.execute_reply": "2024-03-22T21:53:24.254492Z"
    },
    "papermill": {
     "duration": 0.023637,
     "end_time": "2024-03-22T21:53:24.257583",
     "exception": false,
     "start_time": "2024-03-22T21:53:24.233946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34ac626c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T21:53:24.290523Z",
     "iopub.status.busy": "2024-03-22T21:53:24.289650Z",
     "iopub.status.idle": "2024-03-22T22:04:54.864055Z",
     "shell.execute_reply": "2024-03-22T22:04:54.863127Z"
    },
    "papermill": {
     "duration": 690.593695,
     "end_time": "2024-03-22T22:04:54.866539",
     "exception": false,
     "start_time": "2024-03-22T21:53:24.272844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ae7a034e41421f9abaa59da96635a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoConfig\n",
    "\n",
    "accelerator = Accelerator()\n",
    "\n",
    "# Comment/Uncomment and use as per wish\n",
    "\n",
    "# MODEL_PATH = \"/kaggle/input/gemma/transformers/7b-it/2\"\n",
    "# MODEL_PATH = \"/kaggle/input/gemma/transformers/2b-it/2\"\n",
    "# MODEL_PATH = \"/kaggle/input/mistral/pytorch/7b-instruct-v0.1-hf/1\"\n",
    "MODEL_PATH = \"/kaggle/input/mixtral/pytorch/8x7b-instruct-v0.1-hf/1\"\n",
    "# MODEL_PATH = \"/kaggle/input/llama-2/pytorch/7b-chat-hf/1\"\n",
    "# MODEL_PATH = \"/kaggle/input/llama-2/pytorch/13b-chat-hf/1\"\n",
    "\n",
    "# Found a good blog to catch me up fast!\n",
    "# https://huggingface.co/blog/4bit-transformers-bitsandbytes\n",
    "# https://huggingface.co/docs/transformers/v4.38.1/en/quantization#compute-data-type\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit = True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
    "\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    device_map = \"auto\",\n",
    "    trust_remote_code = True,\n",
    "    quantization_config=quantization_config,\n",
    ")\n",
    "\n",
    "# model = model.to_bettertransformer()\n",
    "model = accelerator.prepare(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe962f00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T22:04:54.901203Z",
     "iopub.status.busy": "2024-03-22T22:04:54.900615Z",
     "iopub.status.idle": "2024-03-22T22:04:54.954222Z",
     "shell.execute_reply": "2024-03-22T22:04:54.953371Z"
    },
    "papermill": {
     "duration": 0.07269,
     "end_time": "2024-03-22T22:04:54.956461",
     "exception": false,
     "start_time": "2024-03-22T22:04:54.883771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "# TEST_DF_FILE = '/kaggle/input/llm-prompt-recovery/test.csv'\n",
    "TEST_DF_FILE = '/kaggle/input/combined/test2.csv'\n",
    "SUB_DF_FILE = '/kaggle/input/llm-prompt-recovery/sample_submission.csv'\n",
    "NROWS = None if DEBUG else None\n",
    "\n",
    "if DEBUG:\n",
    "    TEST_DF_FILE = '/kaggle/input/gemma-rewrite-nbroad/nbroad-v1.csv'\n",
    "    SUB_DF_FILE = TEST_DF_FILE\n",
    "\n",
    "tdf = pd.read_csv(TEST_DF_FILE, nrows=NROWS, usecols=['id', 'original_text', 'rewritten_text'])\n",
    "sub = pd.read_csv(SUB_DF_FILE, nrows=NROWS, usecols=['id', 'rewrite_prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "665ff7fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T22:04:54.990559Z",
     "iopub.status.busy": "2024-03-22T22:04:54.990236Z",
     "iopub.status.idle": "2024-03-22T22:04:54.997218Z",
     "shell.execute_reply": "2024-03-22T22:04:54.996246Z"
    },
    "papermill": {
     "duration": 0.026274,
     "end_time": "2024-03-22T22:04:54.999386",
     "exception": false,
     "start_time": "2024-03-22T22:04:54.973112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def truncate_txt(text, length):\n",
    "    text_list = text.split()\n",
    "    \n",
    "    if len(text_list) <= length:\n",
    "        return text\n",
    "    \n",
    "    return \" \".join(text_list[:length])\n",
    "\n",
    "\n",
    "def gen_prompt(og_text, rewritten_text):\n",
    "    \n",
    "    # Truncate the texts to first 200 words for now\n",
    "    # As we are having memory issues on Mixtral8x7b\n",
    "    og_text = truncate_txt(og_text, 200)\n",
    "    rewritten_text = truncate_txt(rewritten_text, 200)\n",
    "    \n",
    "    return f\"\"\"Original Text:\\\"\"\"{og_text}\\\"\"\"\\nRewritten Text:\\\"\"\"{rewritten_text}\\\"\"\"\\nGiven are 2 texts, the Rewritten text was created from the Original text using the google Gemma model. You are trying to understand how the original text was transformed into a new version. Analyzing the changes in style, theme, etc., please come up with a prompt that must have been used to guide the transformation from the original to the rewritten text. Start directly with the prompt, that's all I need. Output should be one line ONLY.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca5eb73",
   "metadata": {
    "papermill": {
     "duration": 0.016447,
     "end_time": "2024-03-22T22:04:55.032297",
     "exception": false,
     "start_time": "2024-03-22T22:04:55.015850",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# QLoRA Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc92386f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T22:04:55.067801Z",
     "iopub.status.busy": "2024-03-22T22:04:55.066861Z",
     "iopub.status.idle": "2024-03-22T22:04:56.249137Z",
     "shell.execute_reply": "2024-03-22T22:04:56.247958Z"
    },
    "papermill": {
     "duration": 1.202406,
     "end_time": "2024-03-22T22:04:56.251733",
     "exception": false,
     "start_time": "2024-03-22T22:04:55.049327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"]\n",
    ")\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "490177a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T22:04:56.285432Z",
     "iopub.status.busy": "2024-03-22T22:04:56.285100Z",
     "iopub.status.idle": "2024-03-22T22:04:56.292903Z",
     "shell.execute_reply": "2024-03-22T22:04:56.291900Z"
    },
    "papermill": {
     "duration": 0.02682,
     "end_time": "2024-03-22T22:04:56.295184",
     "exception": false,
     "start_time": "2024-03-22T22:04:56.268364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=4,\n",
    "    gradient_accumulation_steps=1,\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=25,\n",
    "    logging_steps=25,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.001,\n",
    "    fp16=False,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    report_to=\"wandb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9c5e749",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T22:04:56.329948Z",
     "iopub.status.busy": "2024-03-22T22:04:56.329451Z",
     "iopub.status.idle": "2024-03-22T22:04:56.578473Z",
     "shell.execute_reply": "2024-03-22T22:04:56.577360Z"
    },
    "papermill": {
     "duration": 0.2723,
     "end_time": "2024-03-22T22:04:56.583355",
     "exception": false,
     "start_time": "2024-03-22T22:04:56.311055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>rewrite_prompt</th>\n",
       "      <th>rewritten_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enrique Eduardo Palos Reyes (born 31 May 1986 ...</td>\n",
       "      <td>Rewrite the text as if it were an epic poem ab...</td>\n",
       "      <td>Sure, here's the rewritten text as if it were ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jennifer Tress begins a presentation at George...</td>\n",
       "      <td>Express this as a lullaby.</td>\n",
       "      <td>Sure, here is the lullaby in the form requeste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Carl-Gustaf Rossby Research Medal is the h...</td>\n",
       "      <td>Style it as a passionate telenovela scene.</td>\n",
       "      <td>(The flickering candlelight casts a warm glow ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wallace M. Alexander (1869–1939) was an Americ...</td>\n",
       "      <td>Recast it as a survival guide for a deserted i...</td>\n",
       "      <td>Sure, here's the recast:\\n\\nWallace M. Alexand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Guinea turaco (Tauraco persa), also known ...</td>\n",
       "      <td>Write the text as if it were a command issued ...</td>\n",
       "      <td>Hear ye, hear ye, my dear subjects! I command ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       original_text  \\\n",
       "0  Enrique Eduardo Palos Reyes (born 31 May 1986 ...   \n",
       "1  Jennifer Tress begins a presentation at George...   \n",
       "2  The Carl-Gustaf Rossby Research Medal is the h...   \n",
       "3  Wallace M. Alexander (1869–1939) was an Americ...   \n",
       "4  The Guinea turaco (Tauraco persa), also known ...   \n",
       "\n",
       "                                      rewrite_prompt  \\\n",
       "0  Rewrite the text as if it were an epic poem ab...   \n",
       "1                         Express this as a lullaby.   \n",
       "2         Style it as a passionate telenovela scene.   \n",
       "3  Recast it as a survival guide for a deserted i...   \n",
       "4  Write the text as if it were a command issued ...   \n",
       "\n",
       "                                      rewritten_text  \n",
       "0  Sure, here's the rewritten text as if it were ...  \n",
       "1  Sure, here is the lullaby in the form requeste...  \n",
       "2  (The flickering candlelight casts a warm glow ...  \n",
       "3  Sure, here's the recast:\\n\\nWallace M. Alexand...  \n",
       "4  Hear ye, hear ye, my dear subjects! I command ...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# `LLM Prompt Recovery - Synthetic Datastore dataset` by @dschettler8845\n",
    "df1 = pd.read_csv(\"/kaggle/input/llm-prompt-recovery-synthetic-datastore/gemma1000_w7b.csv\")\n",
    "df1 = df1[[\"original_text\", \"rewrite_prompt\", \"gemma_7b_rewritten_text_temp0\"]]\n",
    "df1 = df1.rename(columns={\"gemma_7b_rewritten_text_temp0\":\"rewritten_text\"})\n",
    "df1.head(2)\n",
    "\n",
    "# `3000 Rewritten texts - Prompt recovery Challenge` by @dipamc77\n",
    "df2 = pd.read_csv(\"/kaggle/input/3000-rewritten-texts-prompt-recovery-challenge/prompts_0_500_wiki_first_para_3000.csv\")\n",
    "df2.head(2)\n",
    "\n",
    "# Merge all datasets\n",
    "df = pd.concat([df1, df2], axis=0)\n",
    "df = df.sample(2000).reset_index(drop=True) # to reduce training time we are only using 2k samples\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11ebfccb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T22:04:56.619021Z",
     "iopub.status.busy": "2024-03-22T22:04:56.618103Z",
     "iopub.status.idle": "2024-03-22T22:04:56.630700Z",
     "shell.execute_reply": "2024-03-22T22:04:56.629770Z"
    },
    "papermill": {
     "duration": 0.032845,
     "end_time": "2024-03-22T22:04:56.633033",
     "exception": false,
     "start_time": "2024-03-22T22:04:56.600188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure, here is the arrangement to be arranged:\\n\\n**Arrange for the launch of the Tata 'Swach' water purifier in rural areas:**\\n\\n**Key points:**\\n\\n* The Tata Group has launched a new low-cost water purifier, the Tata 'Swach', aimed at lower-income households in rural areas.\\n* The purifier is less than one metre tall and does not require running water or electricity to operate.\\n* The firm is hoping to revolutionise the business of providing clean water, a lack of which affects almost one billion people globally.\\n* The device is the result of a decade of research and development.\\n\\n**Steps to be arranged:**\\n\\n1. **Identify target areas:** Determine the specific rural areas where the Tata 'Swach' purifier will be most effective.\\n2. **Distribution channels:** Set up a network of distribution channels to reach the target areas.\\n3. **Training and education:** Train local communities on how to use and maintain the purifier.\\n4. **Affordability:** Ensure that the purifier is affordable for lower-income households.\\n5. **Sustainability:** Develop a sustainable business model to ensure the long-term viability of the program.\\n6. **Impact assessment:** Monitor the impact of the purifier on the health and well-being of beneficiaries.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict = {\n",
    "    \"id\": [str(x) for x in range(0,len(df))],\n",
    "    \"original_text\": [str(x) for x in df.original_text],\n",
    "    \"rewrite_prompt\": [str(x) for x in df.rewrite_prompt],\n",
    "    \"rewritten_text\": [str(x) for x in df.rewritten_text],\n",
    "}\n",
    "dict['rewritten_text'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ee2c32f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T22:04:56.669150Z",
     "iopub.status.busy": "2024-03-22T22:04:56.668778Z",
     "iopub.status.idle": "2024-03-22T22:04:56.780565Z",
     "shell.execute_reply": "2024-03-22T22:04:56.779572Z"
    },
    "papermill": {
     "duration": 0.132502,
     "end_time": "2024-03-22T22:04:56.782880",
     "exception": false,
     "start_time": "2024-03-22T22:04:56.650378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'original_text', 'rewrite_prompt', 'rewritten_text'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = Dataset.from_dict(dict)\n",
    "ds[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "949f4318",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T22:04:56.866070Z",
     "iopub.status.busy": "2024-03-22T22:04:56.865648Z",
     "iopub.status.idle": "2024-03-22T22:05:26.308220Z",
     "shell.execute_reply": "2024-03-22T22:05:26.307188Z"
    },
    "papermill": {
     "duration": 29.464099,
     "end_time": "2024-03-22T22:05:26.310321",
     "exception": false,
     "start_time": "2024-03-22T22:04:56.846222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4113b5464c344a5b99b2e70077700bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'original_text', 'rewrite_prompt', 'rewritten_text', 'input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def truncate_text(text, max_len): #without this    \n",
    "    text_split = text.split()    \n",
    "    if len(text_split)<=max_len:\n",
    "        return text\n",
    "    else:\n",
    "        return \" \".join(text_split[:max_len])\n",
    "\n",
    "def tokenize(example):\n",
    "    for ot, rt, rp in zip(example[\"original_text\"], example[\"rewritten_text\"], example[\"rewrite_prompt\"]):\n",
    "        original_text = truncate_text(ot, 200)\n",
    "        rewritten_text = truncate_text(rt, 200)\n",
    "        rewrite_prompt = truncate_text(rp, 100)\n",
    "    \n",
    "        template = f\"\"\"Original Text:\\\"\"\"{original_text}\\\"\"\"\\nRewritten Text:\\\"\"\"{rewritten_text}\\\"\"\"\\nGiven are 2 texts, the Rewritten text was created from the Original text using the google Gemma model. You are trying to understand how the original text was transformed into a new version. Analyzing the changes in style, theme, etc., please come up with a prompt that must have been used to guide the transformation from the original to the rewritten text. Start directly with the prompt, that's all I need. Output should be one line ONLY.\\n\\nResponse:\\n\\\"{rewrite_prompt}\\\"\"\"\"\n",
    "        tkn = tokenizer(template, padding=True)\n",
    "    return {**tkn}\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    \n",
    "ds_tokenize = ds.map(tokenize)\n",
    "ds_tokenize[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7b39943",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T22:05:26.348213Z",
     "iopub.status.busy": "2024-03-22T22:05:26.347849Z",
     "iopub.status.idle": "2024-03-22T22:05:26.367313Z",
     "shell.execute_reply": "2024-03-22T22:05:26.366546Z"
    },
    "papermill": {
     "duration": 0.040592,
     "end_time": "2024-03-22T22:05:26.369394",
     "exception": false,
     "start_time": "2024-03-22T22:05:26.328802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ds_split = ds_tokenize.train_test_split(test_size=0.20)\n",
    "\n",
    "train_ds = ds_split['train']\n",
    "test_ds = ds_split['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "54abded3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T22:05:26.406872Z",
     "iopub.status.busy": "2024-03-22T22:05:26.406198Z",
     "iopub.status.idle": "2024-03-22T22:05:26.410653Z",
     "shell.execute_reply": "2024-03-22T22:05:26.409650Z"
    },
    "papermill": {
     "duration": 0.025089,
     "end_time": "2024-03-22T22:05:26.412694",
     "exception": false,
     "start_time": "2024-03-22T22:05:26.387605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Setting sft parameters\n",
    "# trainer = SFTTrainer(\n",
    "#     model=model,\n",
    "#     train_dataset=dataset,\n",
    "#     peft_config=peft_config,\n",
    "#     max_seq_length= None,\n",
    "#     dataset_text_field=\"original_text\",\n",
    "#     tokenizer=tokenizer,\n",
    "#     args=training_arguments,\n",
    "#     packing= False,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "796f8d66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T22:05:26.453680Z",
     "iopub.status.busy": "2024-03-22T22:05:26.452575Z",
     "iopub.status.idle": "2024-03-22T22:05:26.505311Z",
     "shell.execute_reply": "2024-03-22T22:05:26.504372Z"
    },
    "papermill": {
     "duration": 0.075532,
     "end_time": "2024-03-22T22:05:26.507717",
     "exception": false,
     "start_time": "2024-03-22T22:05:26.432185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, DataCollatorForLanguageModeling\n",
    "trainer = Trainer(\n",
    "    model=model, # lora enabled\n",
    "    train_dataset=ds_tokenize,    \n",
    "    args=TrainingArguments(\n",
    "        per_device_train_batch_size=1,\n",
    "        learning_rate=2e-5,\n",
    "        fp16=True,\n",
    "        output_dir=\".\",\n",
    "        optim=\"paged_adamw_8bit\",\n",
    "        num_train_epochs=1\n",
    "    ),\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
    "    #compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11ff37f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-22T22:05:26.545305Z",
     "iopub.status.busy": "2024-03-22T22:05:26.544435Z",
     "iopub.status.idle": "2024-03-23T03:41:06.624289Z",
     "shell.execute_reply": "2024-03-23T03:41:06.623287Z"
    },
    "papermill": {
     "duration": 20140.100843,
     "end_time": "2024-03-23T03:41:06.626248",
     "exception": false,
     "start_time": "2024-03-22T22:05:26.525405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 5:35:27, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.439500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.065200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.060600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.058400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /kaggle/input/mixtral/pytorch/8x7b-instruct-v0.1-hf/1 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /kaggle/input/mixtral/pytorch/8x7b-instruct-v0.1-hf/1 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /kaggle/input/mixtral/pytorch/8x7b-instruct-v0.1-hf/1 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /kaggle/input/mixtral/pytorch/8x7b-instruct-v0.1-hf/1 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2000, training_loss=0.15590352153778075, metrics={'train_runtime': 20139.6274, 'train_samples_per_second': 0.099, 'train_steps_per_second': 0.099, 'total_flos': 6.923214307472179e+16, 'train_loss': 0.15590352153778075, 'epoch': 1.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "763cc7dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T03:41:06.662588Z",
     "iopub.status.busy": "2024-03-23T03:41:06.661448Z",
     "iopub.status.idle": "2024-03-23T03:41:07.221339Z",
     "shell.execute_reply": "2024-03-23T03:41:07.220211Z"
    },
    "papermill": {
     "duration": 0.580272,
     "end_time": "2024-03-23T03:41:07.223894",
     "exception": false,
     "start_time": "2024-03-23T03:41:06.643622",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in /kaggle/input/mixtral/pytorch/8x7b-instruct-v0.1-hf/1 - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer.model.save_pretrained(\"My fine tuned model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c52594",
   "metadata": {
    "papermill": {
     "duration": 0.033356,
     "end_time": "2024-03-23T03:41:07.279295",
     "exception": false,
     "start_time": "2024-03-23T03:41:07.245939",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Test / Validate Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a04b9b42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T03:41:07.319956Z",
     "iopub.status.busy": "2024-03-23T03:41:07.319001Z",
     "iopub.status.idle": "2024-03-23T03:41:07.323479Z",
     "shell.execute_reply": "2024-03-23T03:41:07.322489Z"
    },
    "papermill": {
     "duration": 0.027327,
     "end_time": "2024-03-23T03:41:07.325501",
     "exception": false,
     "start_time": "2024-03-23T03:41:07.298174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_data = pd.read_csv(open(\"/kaggle/input/combined/test2.csv\"))\n",
    "# test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9033a999",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T03:41:07.366778Z",
     "iopub.status.busy": "2024-03-23T03:41:07.365917Z",
     "iopub.status.idle": "2024-03-23T03:41:07.370547Z",
     "shell.execute_reply": "2024-03-23T03:41:07.369678Z"
    },
    "papermill": {
     "duration": 0.027357,
     "end_time": "2024-03-23T03:41:07.372653",
     "exception": false,
     "start_time": "2024-03-23T03:41:07.345296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test_ds = Dataset.from_dict({\n",
    "#     \"id\": [str(x) for x in range(0,len(df))],\n",
    "#     \"original_text\": [x for x in df.original_text],\n",
    "#     \"rewritten_text\": [x for x in df.rewritten_text],\n",
    "# })\n",
    "# test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7de3439e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T03:41:07.413664Z",
     "iopub.status.busy": "2024-03-23T03:41:07.413319Z",
     "iopub.status.idle": "2024-03-23T03:41:07.418126Z",
     "shell.execute_reply": "2024-03-23T03:41:07.417193Z"
    },
    "papermill": {
     "duration": 0.027185,
     "end_time": "2024-03-23T03:41:07.420131",
     "exception": false,
     "start_time": "2024-03-23T03:41:07.392946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def tokenize_test(example):\n",
    "#     for ot, rt in zip(example[\"original_text\"], example[\"rewritten_text\"]):\n",
    "#         original_text = truncate_text(ot, 200)\n",
    "#         rewritten_text = truncate_text(rt, 200)\n",
    "    \n",
    "#         template = f\"Instruction:\\nGiven 2 texts: Original Text and Rewritten Text. An LLM is received a prompt from a user asking to rewrite the given Original Text. Based on this prompt, the LLM generated the given Rewritten Text from the given Original Text in a certain way specified in the prompt. Your task is to guess the prompt with which the LLM generated the Rewritten Text.\\nOriginal Text: \\\"{original_text}\\\".\\nRewritten Text: \\\"{rewritten_text}\\\".\\n\\nResponse:\\n\\\"\\\"\"\n",
    "#         tkn = tokenizer(template, padding=True, return_tensors=\"pt\")\n",
    "#     return {**tkn}\n",
    "    \n",
    "# test_ds_tokenized = test_ds.map(tokenize_test)\n",
    "# test_ds_tokenized[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1f5ae1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T03:41:07.461979Z",
     "iopub.status.busy": "2024-03-23T03:41:07.461079Z",
     "iopub.status.idle": "2024-03-23T03:41:07.465181Z",
     "shell.execute_reply": "2024-03-23T03:41:07.464372Z"
    },
    "papermill": {
     "duration": 0.027295,
     "end_time": "2024-03-23T03:41:07.467075",
     "exception": false,
     "start_time": "2024-03-23T03:41:07.439780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6ed4ca54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T03:41:07.504230Z",
     "iopub.status.busy": "2024-03-23T03:41:07.503908Z",
     "iopub.status.idle": "2024-03-23T03:41:07.508090Z",
     "shell.execute_reply": "2024-03-23T03:41:07.507212Z"
    },
    "papermill": {
     "duration": 0.025104,
     "end_time": "2024-03-23T03:41:07.510089",
     "exception": false,
     "start_time": "2024-03-23T03:41:07.484985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model = model.to(device)\n",
    "\n",
    "# for item in test_ds:\n",
    "#     print(item) # only 1 item so its okay to print out   \n",
    "#     inputs = tokenize_test(item).to(device)\n",
    "#     print(inputs)\n",
    "    \n",
    "#     #model.config.use_cache = False  # silence the warnings.\n",
    "#     outputs = model.generate(**inputs)\n",
    "#     print(outputs)\n",
    "\n",
    "#     text_outputs = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "#     print('\\n\\n', text_outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8e781da8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T03:41:07.546949Z",
     "iopub.status.busy": "2024-03-23T03:41:07.546680Z",
     "iopub.status.idle": "2024-03-23T03:41:07.550477Z",
     "shell.execute_reply": "2024-03-23T03:41:07.549734Z"
    },
    "papermill": {
     "duration": 0.024077,
     "end_time": "2024-03-23T03:41:07.552248",
     "exception": false,
     "start_time": "2024-03-23T03:41:07.528171",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# text = \"Improve the text\"\n",
    "# inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "# print(inputs)\n",
    "\n",
    "# model = model.to(device)\n",
    "# model.config.use_cache = False  # silence the warnings.\n",
    "# outputs = model.generate(**inputs)\n",
    "# print(outputs)\n",
    "\n",
    "# print('\\n\\n', tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7151e138",
   "metadata": {
    "papermill": {
     "duration": 0.017502,
     "end_time": "2024-03-23T03:41:07.587096",
     "exception": false,
     "start_time": "2024-03-23T03:41:07.569594",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4507cb56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T03:41:07.622820Z",
     "iopub.status.busy": "2024-03-23T03:41:07.622559Z",
     "iopub.status.idle": "2024-03-23T03:41:07.641678Z",
     "shell.execute_reply": "2024-03-23T03:41:07.640980Z"
    },
    "papermill": {
     "duration": 0.039013,
     "end_time": "2024-03-23T03:41:07.643487",
     "exception": false,
     "start_time": "2024-03-23T03:41:07.604474",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TEST_DF_FILE = '/kaggle/input/testsmall/smalltest.csv'\n",
    "TEST_DF_FILE = '/kaggle/input/llm-prompt-recovery/test.csv'\n",
    "SUB_DF_FILE = '/kaggle/input/llm-prompt-recovery/sample_submission.csv'\n",
    "NROWS = None if DEBUG else None\n",
    "\n",
    "if DEBUG:\n",
    "    TEST_DF_FILE = '/kaggle/input/gemma-rewrite-nbroad/nbroad-v1.csv'\n",
    "    SUB_DF_FILE = TEST_DF_FILE\n",
    "\n",
    "tdf = pd.read_csv(TEST_DF_FILE, nrows=NROWS, usecols=['id', 'original_text', 'rewritten_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9dfb17cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T03:41:07.680375Z",
     "iopub.status.busy": "2024-03-23T03:41:07.679825Z",
     "iopub.status.idle": "2024-03-23T03:43:45.407366Z",
     "shell.execute_reply": "2024-03-23T03:43:45.406300Z"
    },
    "papermill": {
     "duration": 157.767628,
     "end_time": "2024-03-23T03:43:45.428780",
     "exception": false,
     "start_time": "2024-03-23T03:41:07.661152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/checkpoint.py:61: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "100%|██████████| 1/1 [02:37<00:00, 157.71s/it]\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import re\n",
    "\n",
    "device = accelerator.device\n",
    "tdf['id'] = sub['id'].copy()\n",
    "\n",
    "pbar = tqdm(total=tdf.shape[0])\n",
    "\n",
    "it = iter(tdf.iterrows())\n",
    "idx, row = next(it, (None, None))\n",
    "\n",
    "# https://www.kaggle.com/competitions/llm-prompt-recovery/discussion/481116\n",
    "DEFAULT_TEXT = \"Please improve the following text using the writing style of, maintaining the original meaning but altering the tone, diction, and stylistic elements to match the new style.Enhance the clarity, elegance, and impact of the following text by adopting the writing style of , ensuring the core message remains intact while transforming the tone, word choice, and stylistic features to align with the specified style.\"\n",
    "\n",
    "res = []\n",
    "\n",
    "while idx is not None:\n",
    "    \n",
    "    if (datetime.datetime.now() - start_time) > datetime.timedelta(hours=8, minutes=30):\n",
    "        res.append([row[\"id\"], DEFAULT_TEXT])\n",
    "        idx, row = next(it, (None, None))\n",
    "        pbar.update(1)\n",
    "        continue\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "        \n",
    "    try:        \n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": gen_prompt(row[\"original_text\"], row[\"rewritten_text\"])\n",
    "            }\n",
    "        ]\n",
    "        encoded_input = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", add_generation_prompt=True).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            encoded_output = model.generate(encoded_input, max_new_tokens=50, do_sample=True, pad_token_id=tokenizer.eos_token_id)\n",
    "        \n",
    "        decoded_output = tokenizer.batch_decode(encoded_output, skip_special_tokens=True)[0]\n",
    "        decoded_output = result = re.sub(r\"[\\s\\S]*\\[\\/INST\\]\", '', decoded_output, 1)\n",
    "                \n",
    "        res.append([row[\"id\"], decoded_output])\n",
    "                            \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "        res.append([row[\"id\"], DEFAULT_TEXT])\n",
    "        \n",
    "    finally:\n",
    "        idx, row = next(it, (None, None))\n",
    "        pbar.update(1)\n",
    "\n",
    "        \n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b3a8166f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T03:43:45.466912Z",
     "iopub.status.busy": "2024-03-23T03:43:45.466593Z",
     "iopub.status.idle": "2024-03-23T03:43:45.481206Z",
     "shell.execute_reply": "2024-03-23T03:43:45.480320Z"
    },
    "papermill": {
     "duration": 0.035935,
     "end_time": "2024-03-23T03:43:45.483280",
     "exception": false,
     "start_time": "2024-03-23T03:43:45.447345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sub[\"rewrite_prompt\"] = tdf['rewrite_prompt'].copy()\n",
    "# sub.to_csv(\"submission.csv\", index=False)\n",
    "sub = pd.DataFrame(res, columns=['id', 'rewrite_prompt'])\n",
    "\n",
    "sub.to_csv(\"sample_submission.csv\", index=False)\n",
    "sub.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6baea247",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T03:43:45.522215Z",
     "iopub.status.busy": "2024-03-23T03:43:45.521885Z",
     "iopub.status.idle": "2024-03-23T03:43:45.530369Z",
     "shell.execute_reply": "2024-03-23T03:43:45.529524Z"
    },
    "papermill": {
     "duration": 0.029701,
     "end_time": "2024-03-23T03:43:45.532239",
     "exception": false,
     "start_time": "2024-03-23T03:43:45.502538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>rewrite_prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9559194</td>\n",
       "      <td>\"\"\"\"Rewrite original texts into a creative fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                     rewrite_prompt\n",
       "0  9559194   \"\"\"\"Rewrite original texts into a creative fo..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c7e2df8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T03:43:45.571728Z",
     "iopub.status.busy": "2024-03-23T03:43:45.571390Z",
     "iopub.status.idle": "2024-03-23T03:43:45.576917Z",
     "shell.execute_reply": "2024-03-23T03:43:45.576141Z"
    },
    "papermill": {
     "duration": 0.027978,
     "end_time": "2024-03-23T03:43:45.578828",
     "exception": false,
     "start_time": "2024-03-23T03:43:45.550850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9559194,\n",
       "  ' \"\"\"\"Rewrite original texts into a creative format, using a clever prompt as your guide.\"\"\"\"\"]\"']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7806901,
     "sourceId": 67121,
     "sourceType": "competition"
    },
    {
     "datasetId": 4517764,
     "sourceId": 7731345,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4518936,
     "sourceId": 7733314,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4506214,
     "sourceId": 7747717,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4618975,
     "sourceId": 7871774,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4625219,
     "sourceId": 7880564,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4626238,
     "sourceId": 7882007,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 164836055,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 167917311,
     "sourceType": "kernelVersion"
    },
    {
     "modelInstanceId": 3093,
     "sourceId": 4298,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 3097,
     "sourceId": 4302,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 3900,
     "sourceId": 5112,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 4761,
     "sourceId": 5994,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 8332,
     "sourceId": 11394,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21178.151851,
   "end_time": "2024-03-23T03:43:48.991526",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-22T21:50:50.839675",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0bec8b13d1174f07aeb1c618f26f8f2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0d8f9032eeaa4edd9c2403272993f0d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "322ca79bca29434d9dbf05a6139be960": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3fc26dfda3b54743a24cf43ee82aaa10": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_322ca79bca29434d9dbf05a6139be960",
       "max": 19.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f3d4b80e4d6348008b6f5ffedf4edad6",
       "value": 19.0
      }
     },
     "591659a885224f428adabbcf5c996a48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7ede1ae6e8ab48d58875d85aa4122cfd",
       "max": 2000.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c7aca574180043d9bbf3c407b3e1a6e8",
       "value": 2000.0
      }
     },
     "5e9381efd7e6499aa95e4dc7100e083e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ba035dd0d0af46689d2fe29416954cfb",
       "placeholder": "​",
       "style": "IPY_MODEL_73b2442a4a9347538607868a844721c5",
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "6b78d3eb8f184f84b24f9c9b62931b35": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "73b2442a4a9347538607868a844721c5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7a25f0d0ce4a48e0974ac0485b4e2752": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7ede1ae6e8ab48d58875d85aa4122cfd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8246d527c2624237bff1cafa25d51a1f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8d69bcecc09747138c2adba480d5fdf9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d7e7bb54b1be4ca7ae6454aa8c90f886",
       "placeholder": "​",
       "style": "IPY_MODEL_c6d79ab35dc14b3ebd9f70a0d3fb5ceb",
       "value": "Map: 100%"
      }
     },
     "a4113b5464c344a5b99b2e70077700bc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8d69bcecc09747138c2adba480d5fdf9",
        "IPY_MODEL_591659a885224f428adabbcf5c996a48",
        "IPY_MODEL_a549548e836640699de52903af33901d"
       ],
       "layout": "IPY_MODEL_6b78d3eb8f184f84b24f9c9b62931b35"
      }
     },
     "a549548e836640699de52903af33901d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8246d527c2624237bff1cafa25d51a1f",
       "placeholder": "​",
       "style": "IPY_MODEL_e85b68b2da9d44cfb54a38789050cf0e",
       "value": " 2000/2000 [00:29&lt;00:00, 56.02 examples/s]"
      }
     },
     "b7ae7a034e41421f9abaa59da96635a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5e9381efd7e6499aa95e4dc7100e083e",
        "IPY_MODEL_3fc26dfda3b54743a24cf43ee82aaa10",
        "IPY_MODEL_d66fe3ffa4a44f56b38ec1931e187cf0"
       ],
       "layout": "IPY_MODEL_7a25f0d0ce4a48e0974ac0485b4e2752"
      }
     },
     "ba035dd0d0af46689d2fe29416954cfb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c6d79ab35dc14b3ebd9f70a0d3fb5ceb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "c7aca574180043d9bbf3c407b3e1a6e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d66fe3ffa4a44f56b38ec1931e187cf0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_0d8f9032eeaa4edd9c2403272993f0d3",
       "placeholder": "​",
       "style": "IPY_MODEL_0bec8b13d1174f07aeb1c618f26f8f2e",
       "value": " 19/19 [11:23&lt;00:00, 36.22s/it]"
      }
     },
     "d7e7bb54b1be4ca7ae6454aa8c90f886": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e85b68b2da9d44cfb54a38789050cf0e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f3d4b80e4d6348008b6f5ffedf4edad6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
