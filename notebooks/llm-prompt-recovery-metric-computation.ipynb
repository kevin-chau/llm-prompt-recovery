{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 67121,
     "databundleVersionId": 7806901,
     "sourceType": "competition"
    },
    {
     "sourceId": 7714580,
     "sourceType": "datasetVersion",
     "datasetId": 4505324
    },
    {
     "sourceId": 7729151,
     "sourceType": "datasetVersion",
     "datasetId": 4516155
    },
    {
     "sourceId": 7729275,
     "sourceType": "datasetVersion",
     "datasetId": 4516250
    },
    {
     "sourceId": 7747717,
     "sourceType": "datasetVersion",
     "datasetId": 4506214
    }
   ],
   "dockerImageVersionId": 30665,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LLM Prompt Recovery | Metric Computation\n",
    "\n",
    "**Evaluation Metric Description**\n",
    "\n",
    "```\n",
    "For each row in the submission and corresponding ground truth, sentence-t5-base is used to calculate corresponding embedding vectors. The score for each predicted / expected pair is calculated using the Sharpened Cosine Similarity, using an exponent of 3. The SCS is used to attenuate the generous score given by embedding vectors for incorrect answers. Do not leave any rewrite_prompt blank as null answers will throw an error.\n",
    "```\n",
    "\n",
    "-----------------------------------------\n",
    "In this notebook, I show my own implementation of the evaluation metric and provide a sample CV calculation on nbroad's generated data\n",
    "\n",
    "Steps\n",
    "1. Compute the embeddings of the predicted prompts and the actual prompts using sentence-t5-base from HuggingFace\n",
    "2. For each row, compute C ** 3, where C is the cosine similarity between the predicted prompt and the actual prompt for each row\n",
    "3. Finally, average the predictions across the rows to get the CV score"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -Uq /kaggle/input/sentence-transformers-2-4-0/sentence_transformers-2.4.0-py3-none-any.whl"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-18T03:17:48.308373Z",
     "iopub.execute_input": "2024-03-18T03:17:48.308840Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-29T14:19:21.837844Z",
     "iopub.execute_input": "2024-02-29T14:19:21.838153Z",
     "iopub.status.idle": "2024-02-29T14:19:23.918743Z",
     "shell.execute_reply.started": "2024-02-29T14:19:21.838121Z",
     "shell.execute_reply": "2024-02-29T14:19:23.917914Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "test = pd.read_csv(\"/kaggle/input/gemma-rewrite-nbroad/nbroad-v1.csv\")\n",
    "\n",
    "#reference: https://www.kaggle.com/code/isakatsuyoshi/improve-the-following-text-below\n",
    "test[\"pred\"] = 'Improve the following text below:\\n\\n' + test['rewritten_text'] #dummy prompt\n",
    "\n",
    "test"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-29T14:19:23.919963Z",
     "iopub.execute_input": "2024-02-29T14:19:23.920447Z",
     "iopub.status.idle": "2024-02-29T14:19:24.073878Z",
     "shell.execute_reply.started": "2024-02-29T14:19:23.920419Z",
     "shell.execute_reply": "2024-02-29T14:19:24.07304Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def CVScore(test):\n",
    "    \n",
    "    scs = lambda row: abs((cosine_similarity(row[\"actual_embeddings\"], row[\"pred_embeddings\"])) ** 3)\n",
    "    \n",
    "    model = SentenceTransformer('/kaggle/input/sentence-t5-base-hf/sentence-t5-base')\n",
    "\n",
    "    test[\"actual_embeddings\"] = test[\"rewrite_prompt\"].progress_apply(lambda x: model.encode(x, normalize_embeddings=True, show_progress_bar=False).reshape(1, -1))\n",
    "    test[\"pred_embeddings\"] = test[\"pred\"].progress_apply(lambda x: model.encode(x, normalize_embeddings=True, show_progress_bar=False).reshape(1, -1))\n",
    "    \n",
    "    test[\"score\"] = test.apply(scs, axis=1)\n",
    "    \n",
    "    return np.mean(test['score'])[0][0]\n",
    "    \n",
    "print(f\"CV Score: {CVScore(test)}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-29T14:19:24.075604Z",
     "iopub.execute_input": "2024-02-29T14:19:24.075893Z",
     "iopub.status.idle": "2024-02-29T14:20:35.00079Z",
     "shell.execute_reply.started": "2024-02-29T14:19:24.075867Z",
     "shell.execute_reply": "2024-02-29T14:20:34.999817Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
